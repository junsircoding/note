{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "抓取果壳网列表页的内容，报错标题，url地址，简介，点赞数等：https://www.guokr.com/ask/highlight/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import urllib.parse\n",
    "\n",
    "\n",
    "class GkSpider(scrapy.Spider):\n",
    "    name = 'gk'\n",
    "    allowed_domains = ['guokr.com']\n",
    "    start_urls = ['https://www.guokr.com/ask/highlight/']\n",
    "\n",
    "    def parse(self, response):\n",
    "\n",
    "        # 进行数据的提取\n",
    "        # 先分组，再提取\n",
    "        li_list = response.xpath(\"//ul[@class='ask-list-cp']/li\")\n",
    "        for li in li_list:\n",
    "            item = {}\n",
    "            # 关注数\n",
    "            item[\"focus_nums\"] = li.xpath(\n",
    "                \".//p[@class='ask-focus-nums']/span/text()\").extract_first()\n",
    "            # 回答数\n",
    "            item[\"answer_nums\"] = li.xpath(\n",
    "                \".//p[@class='ask-answer-nums']/span/text()\").extract_first()\n",
    "            # url\n",
    "            item[\"href\"] = li.xpath(\".//h2/a/@href\").extract_first()\n",
    "            # 标题\n",
    "            item[\"title\"] = li.xpath(\".//h2/a/text()\").extract_first()\n",
    "            # 描述\n",
    "            item[\"summary\"] = li.xpath(\n",
    "                \".//p[@class='ask-list-summary']/text()\").extract_first().strip()\n",
    "            # 标签\n",
    "            item[\"tag\"] = li.xpath(\".//a[@class='tag']/text()\").extract()\n",
    "            print(item)\n",
    "\n",
    "        # 寻找下一页的url地址，构造请求，交给引擎，指定callback函数\n",
    "        next_url = response.xpath(\"//a[text()='下一页']/@href\").extract_first()\n",
    "        if next_url is not None:\n",
    "            # next_url = urllib.parse.urljoin(response.url,next_url)\n",
    "            print(\"*\"*100)\n",
    "            # yield scrapy.Request(\n",
    "            #     next_url,\n",
    "            #     callback=self.parse  #用自己来提取下一页的数据\n",
    "            # )\n",
    "\n",
    "            # 使用response.follow方法，发送请求\n",
    "            yield response.follow(\n",
    "                next_url,  # 不完整的url地址，根据response的url拼接完整之后构造request对象\n",
    "                callback=self.parse\n",
    "            )\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3160b320a3d098505f6069b13711aa208a544b025e74a1c73de7d3971407adcc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
