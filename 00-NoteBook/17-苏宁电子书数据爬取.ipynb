{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成苏宁电子书的数据抓取,包括大分类，小分类，图书的名字，连接，作者，出版社，简介等信息，url:http://snbook.suning.com/web/trd-fl/999999/0.htm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import urllib.parse\n",
    "\n",
    "\n",
    "class SuningSpider(scrapy.Spider):\n",
    "    name = 'suning'\n",
    "    allowed_domains = ['suning.com']\n",
    "    start_urls = ['http://snbook.suning.com/web/trd-fl/999999/0.htm']\n",
    "\n",
    "    def parse(self, response):\n",
    "        # 获取大分类\n",
    "        li_list = response.xpath(\"//ul[@class='ulwrap']/li\")\n",
    "        for li in li_list:\n",
    "            item = {}\n",
    "            # 大分类的名字\n",
    "            item[\"b_cate\"] = li.xpath(\"./div[1]/a/text()\").extract_first()\n",
    "            # 小分类分组\n",
    "            a_list = li.xpath(\"./div[2]/a\")\n",
    "            for a in a_list:\n",
    "                # 小分类的名字\n",
    "                item[\"s_cate\"] = a.xpath(\"./text()\").extract_first()\n",
    "                # 小分类的url地址\n",
    "                item[\"s_href\"] = a.xpath(\"./@href\").extract_first()\n",
    "                # print(item)\n",
    "                if item[\"s_href\"] is not None:\n",
    "                    item[\"s_href\"] = urllib.parse.urljoin(\n",
    "                        response.url, item[\"s_href\"])\n",
    "                    # 构造小分类url地址的请求\n",
    "                    yield scrapy.Request(\n",
    "                        item[\"s_href\"],\n",
    "                        callback=self.parse_book_list,\n",
    "                        meta={\"item\": deepcopy(item)}\n",
    "                    )\n",
    "\n",
    "    def parse_book_list(self, response):  # 提取列表页的数据\n",
    "        item = response.meta[\"item\"]\n",
    "        # 获取数据列表页数据的分组\n",
    "        li_list = response.xpath(\n",
    "            \"//div[@class='filtrate-books list-filtrate-books']/ul/li\")\n",
    "        for li in li_list:\n",
    "            item[\"book_name\"] = li.xpath(\n",
    "                \".//div[@class='book-title']/a/text()\").extract_first()\n",
    "            item[\"book_href\"] = li.xpath(\n",
    "                \".//div[@class='book-title']/a/@href\").extract_first()\n",
    "            item[\"book_author\"] = li.xpath(\n",
    "                \".//div[@class='book-author']/a/text()\").extract_first()\n",
    "            # 进入图书详情页\n",
    "            yield scrapy.Request(\n",
    "                item[\"book_href\"],\n",
    "                callback=self.parse_book_price,\n",
    "                meta={\"item\": deepcopy(item)}\n",
    "            )\n",
    "        # 列表页的翻页\n",
    "        # 获取总的页码数\n",
    "        page_count = re.findall(\"var pagecount=(.*?);\",\n",
    "                                response.body.decode())[0]\n",
    "        # 获取当前页码数\n",
    "        current_page = re.findall(\n",
    "            \"var currentPage=(.*?);\", response.body.decode())[0]\n",
    "        if int(current_page) < int(page_count):\n",
    "            # 下一页的url地址\n",
    "            next_url = item[\"s_href\"] + \\\n",
    "                \"?pageNumber={}&sort=0\".format(int(current_page)+1)\n",
    "            # 构造请求\n",
    "            yield scrapy.FormRequest(\n",
    "                next_url,\n",
    "                callback=self.parse_book_list,\n",
    "                formdata={\"ajaxFlag\": \"true\"},\n",
    "                meta={\"item\": item}\n",
    "            )\n",
    "\n",
    "    def parse_book_price(self, response):  # 提取详情页的价格\n",
    "        item = response.meta[\"item\"]\n",
    "        item[\"book_price\"] = re.findall(\n",
    "            \"\\\"bp\\\":'(.*?)',\", response.body.decode())[0]\n",
    "        print(item)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3160b320a3d098505f6069b13711aa208a544b025e74a1c73de7d3971407adcc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
